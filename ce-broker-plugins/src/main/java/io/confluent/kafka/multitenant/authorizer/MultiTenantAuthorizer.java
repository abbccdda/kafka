// (Copyright) [2018 - 2018] Confluent, Inc.

package io.confluent.kafka.multitenant.authorizer;

import io.confluent.kafka.multitenant.MultiTenantPrincipal;
import io.confluent.kafka.multitenant.schema.TenantContext;
import java.util.Arrays;
import java.util.Collections;
import java.util.Map;
import java.util.Set;
import java.util.stream.Collectors;
import kafka.network.RequestChannel;
import kafka.security.auth.Acl;
import kafka.security.auth.All$;
import kafka.security.auth.Allow$;
import kafka.security.auth.Alter$;
import kafka.security.auth.AlterConfigs$;
import kafka.security.auth.Cluster$;
import kafka.security.auth.Delete$;
import kafka.security.auth.Deny$;
import kafka.security.auth.Describe$;
import kafka.security.auth.DescribeConfigs$;
import kafka.security.auth.Operation;
import kafka.security.auth.PermissionType;
import kafka.security.auth.Read$;
import kafka.security.auth.Resource;
import kafka.security.auth.SimpleAclAuthorizer;
import kafka.security.auth.SimpleAclAuthorizer$;
import kafka.security.auth.Write$;
import org.apache.kafka.common.errors.InvalidRequestException;
import org.apache.kafka.common.resource.PatternType;
import org.apache.kafka.common.security.auth.KafkaPrincipal;
import org.apache.kafka.common.utils.SecurityUtils;
import org.apache.kafka.common.utils.Utils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import scala.collection.JavaConversions;

/**
 * Multi-tenant authorizer that supports:
 * <ul>
 *    <li>ACLs with TenantUser:clusterId_userId as principal</li>
 *    <li>ACLs with TenantUser*:clusterId_ as wildcard prefixed principal</li>
 *    <li>ACLs with User:* as wildcard principal (e.g. for brokers or users on other listeners)</li>
 *    <li>Resource patterns with literal resource names clusterId_resourceName</li>
 *    <li>Resource patterns with prefixed resource names clusterId_resourcePrefix</li>
 *    <li>Resource patterns with tenant wildcard resource names using prefixed name clusterId_</li>
 *    <li>Resource patterns with literal wildcard resource name "*" (e.g. for broker ACLs)</li>
 *    <li>Super users configured using the configuration option `super.users`
 *        (e.g. for broker principals)</li>
 *    <li>Tenant super users with access to all tenant resources using tenant principals with
 *        {@link io.confluent.kafka.multitenant.TenantMetadata#isSuperUser} enabled.</li>
 * </ul>
 * Use of tenant prefix:
 * <ul>
 *   <li>Clients configure ACLs for User:userId</li>
 *   <li>Multi-tenant interceptor transforms User:userId to TenantUser:clusterId_userId</li>
 *   <li>ACLs are stored internally in ZooKeeper for TenantUser:clusterId_userId</li>
 *   <li>When tenants describe ACLs, prefix is removed from response by the interceptor</li>
 *   <li>Multi-tenant principal builder generates tenant principal TenantUser:clusterId_userId</li>
 *   <li>Authorizer matches TenantUser principals in ACLs obtained from ZooKeeper against
 *       TenantUser session principal generated by the principal builder.</li>
 *   <li>Non-tenant principals (e.g broker principals) are of the form User:userId in ACLs
 *       as well as session principals</li>
 * </ul>
 * Assumptions:
 * <ul>
 *   <li>All tenant ACLs have principals and resource names with tenant prefix</li>
 *   <li>All non-tenant (e.g. broker) ACLs have principals and resource names that do not
 *       contain prefix of any tenant in the cluster</li>
 *   <li>Tenant principals have type TenantUser, others have type User</li>
 * </ul>
 *
 */
public class MultiTenantAuthorizer extends SimpleAclAuthorizer {

  private static final Logger log = LoggerFactory.getLogger("kafka.authorizer.logger");
  public static final String MAX_ACLS_PER_TENANT_PROP = "confluent.max.acls.per.tenant";
  private static final int ACLS_DISABLED = 0;

  private int maxAclsPerTenant;
  private boolean allowEveryoneIfNoAcl;
  private Set<KafkaPrincipal> superUsers;
  private boolean authorizationDisabled;

  @Override
  public void configure(Map<String, ?> configs) {
    String allowIfNoAcl = (String)
        configs.get(SimpleAclAuthorizer$.MODULE$.AllowEveryoneIfNoAclIsFoundProp());
    allowEveryoneIfNoAcl = allowIfNoAcl != null && Boolean.parseBoolean(allowIfNoAcl);
    String maxAcls = (String) configs.get(MAX_ACLS_PER_TENANT_PROP);
    maxAclsPerTenant = maxAcls != null ? Integer.parseInt(maxAcls) : ACLS_DISABLED;
    authorizationDisabled = maxAclsPerTenant == ACLS_DISABLED;

    String su = (String) configs.get(SimpleAclAuthorizer$.MODULE$.SuperUsersProp());
    if (su != null && !su.trim().isEmpty()) {
      String[] users = su.split(";");
      superUsers = Arrays.stream(users)
          .map(user -> SecurityUtils.parseKafkaPrincipal(user.trim()))
          .collect(Collectors.toSet());
    } else {
      superUsers = Collections.emptySet();
    }

    super.configure(configs);
  }


  // we allow an operation if a user is a super user or if no acls are found and user has
  // configured to allow all users when no acls are found or if no deny acls are found and
  // at least one allow acls matches.
  @Override
  public boolean authorize(RequestChannel.Session session, Operation operation, Resource resource) {
    if (resource.patternType() != PatternType.LITERAL) {
      throw new IllegalArgumentException("Only literal resources are supported, got: "
          + resource.patternType());
    }

    // Always use KafkaPrincipal instance for comparisons since super.users and ACLs are
    // instantiated as KafkaPrincipal
    KafkaPrincipal sessionPrincipal = session.principal();
    String host = session.clientAddress().getHostAddress();

    // Super-users (including non-service-accounts and super.users configured in server.properties)
    // are authorized without checking ACLs. For CCPro, `authorizationDisabled=true` and all requests
    // are authorized.
    boolean authorized = isSuperUser(sessionPrincipal) || authorizationDisabled;

    if (!authorized) {
      String tenantPrefix = sessionPrincipal instanceof MultiTenantPrincipal
          ? ((MultiTenantPrincipal) sessionPrincipal).tenantMetadata().tenantPrefix() : "";
      KafkaPrincipal principal = sessionPrincipal.getClass() != KafkaPrincipal.class
          ? new KafkaPrincipal(sessionPrincipal.getPrincipalType(), sessionPrincipal.getName())
          : sessionPrincipal;
      KafkaPrincipal wildcardPrincipal = tenantPrefix.isEmpty() ? Acl.WildCardPrincipal() :
          new KafkaPrincipal(MultiTenantPrincipal.TENANT_WILDCARD_USER_TYPE, tenantPrefix);

      if (resource.resourceType() == Cluster$.MODULE$) {
        String prefixedCluster = tenantPrefix + resource.name();
        resource = new Resource(resource.resourceType(), prefixedCluster, resource.patternType());
      }

      Set<Acl> acls = JavaConversions.setAsJavaSet(getMatchingAcls(resource.resourceType(),
          resource.name()));

      authorized = isEmptyAclAndAuthorized(resource, acls);
      if (!authorized) {
        // Check if there is any Deny acl match that would disallow this operation.
        boolean denyMatch = userMatch(Deny$.MODULE$, operation, resource, principal,
            wildcardPrincipal,
            host, acls);

        // Check if there are any Allow ACLs which would allow this operation.
        // Allowing read, write, delete, or alter implies allowing describe.
        // See #{org.apache.kafka.common.acl.AclOperation} for more details about ACL inheritance.
        Set<Operation> allowOps;
        if (operation == Describe$.MODULE$) {
          allowOps = Utils
              .mkSet(Describe$.MODULE$, Read$.MODULE$, Write$.MODULE$, Delete$.MODULE$,
                  Alter$.MODULE$);
        } else if (operation == DescribeConfigs$.MODULE$) {
          allowOps = Utils.mkSet(DescribeConfigs$.MODULE$, AlterConfigs$.MODULE$);
        } else {
          allowOps = Collections.singleton(operation);
        }

        final Resource requestedResource = resource;
        boolean allowMatch = allowOps.stream().anyMatch(op ->
            userMatch(Allow$.MODULE$, op, requestedResource, principal, wildcardPrincipal, host,
                acls));

        authorized = !denyMatch && allowMatch;
      }
    }

    logAuditMessage(sessionPrincipal, authorized, operation, resource, host);
    return authorized;
  }

  @Override
  public void close() {
    super.close();
  }

  private boolean userMatch(PermissionType permissionType, Operation op, Resource resource,
      KafkaPrincipal principal, KafkaPrincipal wildcardPrincipal, String host, Set<Acl> acls) {
    return aclMatch(op, resource, principal, wildcardPrincipal, host, permissionType, acls);
  }

  private boolean aclMatch(Operation op, Resource resource, KafkaPrincipal principal,
      KafkaPrincipal wildcardPrincipal, String host, PermissionType permissionType, Set<Acl> acls) {
    for (Acl acl : acls) {
      if (acl.permissionType().equals(permissionType)
          && principalMatch(acl.principal(), principal, wildcardPrincipal)
          && (op.equals(acl.operation()) || acl.operation().equals(All$.MODULE$))
          && (acl.host().equals(host) || acl.host().equals(Acl.WildCardHost()))) {
        log
            .debug("operation = {} on resource = {} from host = {} is {} based on acl = {}",
                op, resource, host, permissionType, acl);
        return true;
      }
    }
    return false;
  }

  private boolean principalMatch(KafkaPrincipal aclPrincipal, KafkaPrincipal principal,
      KafkaPrincipal wildcardPrincipal) {
    return aclPrincipal.equals(principal)
        || aclPrincipal.equals(wildcardPrincipal);
  }

  private boolean isEmptyAclAndAuthorized(Resource resource, Set<Acl> acls) {
    if (acls.isEmpty()) {
      log
          .debug("No acl found for resource {}, authorized = {}", resource, allowEveryoneIfNoAcl);
      return allowEveryoneIfNoAcl;
    } else {
      return false;
    }
  }

  private boolean isSuperUser(KafkaPrincipal userPrincipal) {
    boolean multiTenantSuperUser = (userPrincipal instanceof MultiTenantPrincipal)
        && ((MultiTenantPrincipal) userPrincipal).tenantMetadata().isSuperUser;
    if (multiTenantSuperUser || superUsers.contains(userPrincipal)) {
      log
          .debug("principal = {} is a super user, allowing operation without checking acls.",
              userPrincipal);
      return true;
    } else {
      return false;
    }
  }

  @Override
  public void addAcls(scala.collection.immutable.Set<Acl> acls, Resource resource) {
    checkAclsEnabled();
    if (acls.isEmpty()) {
      return;
    }

    // Sanity check tenant ACLs. All tenant ACLs have principal containing tenant prefix
    // and resource names starting with tenant prefix. Also verify that the total number
    // of acls for the tenant doesn't exceed the configured maximum after this add.
    //
    // Note: we are also assuming that there will be no ACLs for tenant resources
    // with non-tenant principals (e.g broker ACLs will not specify tenant resource names)
    // We don't have a way to verify this, but describe/delete filters rely on this assumption.
    String firstTenantPrefix = null;
    KafkaPrincipal firstPrincipal = acls.head().principal();
    if (MultiTenantPrincipal.isTenantPrincipal(firstPrincipal)) {
      firstTenantPrefix = tenantPrefix(firstPrincipal.getName());
      if (!resource.name().startsWith(firstTenantPrefix)) {
        log.error("Unexpected ACL request for resource {} without tenant prefix {}",
            resource, firstTenantPrefix);
        throw new IllegalStateException("Internal error: Could not create ACLs for " + resource);
      }
      if (maxAclsPerTenant != Integer.MAX_VALUE
          && acls.size() + tenantAclCount(firstTenantPrefix) > maxAclsPerTenant) {
        throw new InvalidRequestException("ACLs not created since it will exceed the limit "
            + maxAclsPerTenant);
      }
    }

    final String tenantPrefix = firstTenantPrefix;
    Set<Acl> aclsToAdd = JavaConversions.setAsJavaSet(acls);
    if (aclsToAdd.stream().anyMatch(acl -> !inScope(acl.principal(), tenantPrefix))) {
      log.error("ACL requests contain invalid tenant principal {}", aclsToAdd);
      throw new IllegalStateException("Internal error: Could not create ACLs for " + resource);
    }

    super.addAcls(acls, resource);
  }


  @Override
  public boolean removeAcls(scala.collection.immutable.Set<Acl> aclsTobeRemoved, Resource resource) {
    checkAclsEnabled();
    return super.removeAcls(aclsTobeRemoved, resource);
  }

  @Override
  public boolean removeAcls(Resource resource) {
    checkAclsEnabled();
    return super.removeAcls(resource);
  }

  @Override
  public scala.collection.immutable.Set<Acl> getAcls(Resource resource) {
    checkAclsEnabled();
    return super.getAcls(resource);
  }

  @Override
  public scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> getAcls(KafkaPrincipal principal) {
    checkAclsEnabled();
    return super.getAcls(principal);
  }

  @Override
  public scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> getAcls() {
    checkAclsEnabled();
    return super.getAcls();
  }

  /**
   * Log using the same format as SimpleAclAuthorizer:
   * <pre>
   *  def logMessage: String = {
   *    val authResult = if (authorized) "Allowed" else "Denied"
   *    s"Principal = $principal is $authResult Operation = $operation from host = $host on resource
   * = $resource"
   *  }
   * </pre>
   */
  private void logAuditMessage(KafkaPrincipal principal, boolean authorized, Operation op,
      Resource resource, String host) {
    String logMessage = "Principal = {} is {} Operation = {} from host = {} on resource = {}";
    if (authorized) {
      log.debug(logMessage, principal, "Allowed", op, host, resource);
    } else {
      log.info(logMessage, principal, "Denied", op, host, resource);
    }
  }

  private String tenantPrefix(String name) {
    int index = name.indexOf(TenantContext.DELIMITER);
    if (index == -1) {
      throw new InvalidRequestException("Invalid tenant principal in ACL: " + name);
    } else {
      return name.substring(0, index + 1);
    }
  }

  // Check whether `principal` is within the same tenant (or non-tenant) scope
  // If `tenantPrefix` is non-null, principal must be a tenant principal with
  // the same prefix since ACL requests cannot contain ACLs of multiple tenants.
  // If `tenantPrefix` is null, principal must not be a tenant principal since
  // requests on listeners without the tenant interceptor are not allowed to
  // access tenant ACLs.
  private boolean inScope(KafkaPrincipal principal, String tenantPrefix) {
    if (tenantPrefix != null && !tenantPrefix.isEmpty()) {
      return MultiTenantPrincipal.isTenantPrincipal(principal)
          && principal.getName().startsWith(tenantPrefix);
    } else {
      return !MultiTenantPrincipal.isTenantPrincipal(principal);
    }
  }

  private long tenantAclCount(String tenantPrefix) {
    return JavaConversions.asJavaCollection(getAcls().values()).stream()
        .flatMap(acls -> JavaConversions.asJavaCollection(acls).stream())
        .filter(acl -> inScope(acl.principal(), tenantPrefix))
        .collect(Collectors.counting());
  }

  private void checkAclsEnabled() {
    if (authorizationDisabled) {
      throw new InvalidRequestException("Confluent Cloud Professional does not support ACLs");
    }
  }
}

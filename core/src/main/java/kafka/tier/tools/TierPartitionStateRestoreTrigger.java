/*
 Copyright 2020 Confluent Inc.
 */

package kafka.tier.tools;

import com.fasterxml.jackson.core.JsonProcessingException;
import kafka.log.Log;
import kafka.server.KafkaConfig;
import kafka.tier.TopicIdPartition;
import kafka.tier.domain.TierPartitionForceRestore;
import kafka.tier.state.FileTierPartitionState;
import kafka.tier.state.TierPartitionStatus;
import kafka.tier.state.Header;
import kafka.tier.store.TierObjectStore;
import kafka.tier.store.TierObjectStoreConfig;
import kafka.tier.store.TierObjectStoreUtils;
import kafka.tier.tools.common.RestoreOutput;
import kafka.tier.topic.TierTopic;
import net.sourceforge.argparse4j.ArgumentParsers;
import net.sourceforge.argparse4j.inf.ArgumentParser;
import net.sourceforge.argparse4j.inf.ArgumentParserException;
import net.sourceforge.argparse4j.inf.Namespace;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.utils.Utils;

import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.math.BigInteger;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.nio.file.StandardOpenOption;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Optional;
import java.util.Properties;
import java.util.UUID;

/**
 * A tool that injects PartitionForceRestore events into TierTopic for a provided list of
 * TopicIdPartition. This is helpful in restoring a blessed TierPartitionState.
 *
 * SAMPLE USAGE:
 * $> bin/kafka-run-class.sh \
 *     kafka.tier.tools.TierPartitionStateRestoreTrigger \
 *        --tier.config /path/to/config.properties \
 *        --input.json /path/to/comparator.json
 *        --output.json /path/to/restored.json
 */
public class TierPartitionStateRestoreTrigger {
    public static final String RESTORE_INPUT_CONFIG = "input.json";
    public static final String RESTORE_INPUT_DOC = "JSON input file generated by "
            + "kafka.tier.tools.TierMetadataComparator and reviewed by an administrator. This "
            + "file contains paths to partitions and replica TierPartitionState(s) to choose to "
            + "restore.";

    public static final String RESTORE_OUTPUT_CONFIG = "output.json";
    public static final String RESTORE_OUTPUT_DOC = "Path for output file where recovery "
            + "information will be emitted, including TierPartitionForceRestore metadata.";

    public static final List<String> RECOVERY_REQUIRED_PROPERTIES = Arrays.asList(
            KafkaConfig.TierMetadataNamespaceProp(),
            KafkaConfig.TierBackendProp(),
            KafkaConfig.TierS3RegionProp(),
            KafkaConfig.TierS3BucketProp(),
            KafkaConfig.TierS3PrefixProp(),
            KafkaConfig.TierS3AwsAccessKeyIdProp(),
            KafkaConfig.TierS3AwsSecretAccessKeyProp(),
            KafkaConfig.TierGcsRegionProp(),
            KafkaConfig.TierGcsBucketProp(),
            KafkaConfig.TierGcsPrefixProp(),
            KafkaConfig.TierGcsCredFilePathProp(),
            KafkaConfig.TierGcsWriteChunkSizeProp());

    // Create the CLI argument parser.
    private static ArgumentParser createArgParser() {
        ArgumentParser parser = ArgumentParsers
            .newArgumentParser(TierPartitionStateRestoreTrigger.class.getName())
            .defaultHelp(true)
            .description("Provides a command to restore partition states using a "
                    + "TierPartitionForceRestore event.");
        parser.addArgument(RecoveryUtils.makeArgument(RecoveryUtils.TIER_PROPERTIES_CONF_FILE_CONFIG))
            .dest(RecoveryUtils.TIER_PROPERTIES_CONF_FILE_CONFIG)
            .type(String.class)
            .required(true)
            .help(RecoveryUtils.TIER_PROPERTIES_CONF_FILE_DOC);
        parser.addArgument(RecoveryUtils.makeArgument(TierPartitionStateRestoreTrigger.RESTORE_INPUT_CONFIG))
            .dest(TierPartitionStateRestoreTrigger.RESTORE_INPUT_CONFIG)
            .type(String.class)
            .required(true)
            .help(TierPartitionStateRestoreTrigger.RESTORE_INPUT_DOC);
        parser.addArgument(RecoveryUtils.makeArgument(TierPartitionStateRestoreTrigger.RESTORE_OUTPUT_CONFIG))
                .dest(TierPartitionStateRestoreTrigger.RESTORE_OUTPUT_CONFIG)
                .type(String.class)
                .required(true)
                .help(TierPartitionStateRestoreTrigger.RESTORE_OUTPUT_DOC);
        return parser;
    }

    static TierObjectStore getObjectStore(Properties props) {
        final TierObjectStore.Backend backend = TierObjectStore.Backend.valueOf(props.getProperty(KafkaConfig.TierBackendProp()));
        final TierObjectStoreConfig config = TierObjectStoreUtils.generateBackendConfig(backend, props);
        return TierObjectStoreFactory.getObjectStoreInstance(backend, config);
    }

    private static List<RestoreOutput.ComparatorOutput> getComparatorOutput(Path inputJsonFile) {
        if (Files.notExists(inputJsonFile) || !Files.isRegularFile(inputJsonFile)) {
            throw new IllegalArgumentException("Incorrect json file provided: " + inputJsonFile);
        }
        try {
            return RestoreOutput.ComparatorOutput.readJsonFromFile(inputJsonFile);
        } catch (JsonProcessingException e) {
            throw new IllegalStateException("Couldn't parse provided input JSON", e);
        } catch (IOException e) {
            throw new IllegalArgumentException("Incorrect JSON file provided: " + inputJsonFile, e);
        }
    }

    // Main entry point for the CLI tool.
    private static void run(ArgumentParser parser, Namespace args) throws Exception {
        final String propertiesConfFile =
            args.getString(RecoveryUtils.TIER_PROPERTIES_CONF_FILE_CONFIG).trim();
        final Properties props;
        try {
            List<String> allProps = new ArrayList<>();
            allProps.addAll(RECOVERY_REQUIRED_PROPERTIES);
            allProps.addAll(ProducerConfig.configNames());
            props = Utils.loadProps(propertiesConfFile, allProps);
        } catch (IOException e) {
            throw new ArgumentParserException(
                String.format("Can not load properties from file: '%s'", propertiesConfFile),
                e,
                parser);
        }

        final String bootstrapServers = props.getProperty(
                ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "").trim();
        if (bootstrapServers.isEmpty()) {
            throw new ArgumentParserException(
                String.format(
                    "The provided properties conf file: '%s' can not contain empty or absent" +
                    " bootstrap servers as value for the property: '%s'",
                    propertiesConfFile,
                    ProducerConfig.BOOTSTRAP_SERVERS_CONFIG),
                parser);
        }
        final String tierTopicNamespace =
            props.getProperty(KafkaConfig.TierMetadataNamespaceProp(), "");
        final String inputPath =
                args.getString(TierPartitionStateRestoreTrigger.RESTORE_INPUT_CONFIG).trim();

        final String tierTopicName = TierTopic.topicName(tierTopicNamespace);
        final String outputPath = args.getString(TierPartitionStateRestoreTrigger.RESTORE_OUTPUT_CONFIG).trim();
        File file = new File(outputPath);
        if (file.exists() && !file.delete())
            throw new IOException("Cannot overwrite existing file at " + outputPath);
        if (!file.createNewFile())
            throw new IOException("Could not create output file at path " + outputPath);

        try (Producer<byte[], byte[]> producer = RecoveryUtils.createTierTopicProducer(
                props,
                TierPartitionStateRestoreTrigger.class.getSimpleName())) {
            final TierObjectStore objectStore = getObjectStore(props);
            final int numTierTopicPartitions = RecoveryUtils.getNumPartitions(producer,
                    tierTopicName);
            try {
                final List<RestoreOutput.ComparatorOutput> comparatorOutput = getComparatorOutput(Paths.get(inputPath));
                for (RestoreOutput.ComparatorOutput replica : comparatorOutput) {
                    if (!replica.choice().validationSuccess()) {
                        System.out.println("Comparator did not produce a valid injection for " + replica);
                    } else {
                        TierPartitionForceRestore restore = injectState(tierTopicName,
                                numTierTopicPartitions, producer, objectStore, replica);
                        replica.setTierPartitionForceRestore(restore);
                    }
                }

                try (FileOutputStream fos = new FileOutputStream(file)) {
                    RestoreOutput.ComparatorOutput.writeJsonToFile(comparatorOutput, fos);
                }
            } finally {
                objectStore.close();
            }
        }
    }

    private static TierPartitionForceRestore injectState(String tierTopicName,
                                                         int numTierTopicPartitions,
                                                         Producer<byte[], byte[]> producer,
                                                         TierObjectStore objectStore,
                                                         RestoreOutput.ComparatorOutput replica) throws Exception {
        final File file = replica.choice().path().toFile();
        final TopicPartition topicPartition = Log.parseTopicPartitionName(file.getParentFile());
        try (FileChannel fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ)) {
            System.out.println(String.format("Attempting recovery for %s @ %s",
                    topicPartition, file));
            Optional<Header> headerOpt = FileTierPartitionState.readHeader(fileChannel);
            if (!headerOpt.isPresent())
                throw new Exception("Header is not present for TierPartitionState being recovered");

            final Header header = headerOpt.get();
            if (header.status() != TierPartitionStatus.ERROR)
                throw new Exception("Header is not in error status " + header.toString());

            final UUID restoreUuid = UUID.randomUUID();
            final String hash = computeMd5(fileChannel);
            final TopicIdPartition topicIdPartition = new TopicIdPartition(topicPartition.topic(),
                    header.topicId(), topicPartition.partition());
            final TierPartitionForceRestore restoreEvent =
                    new TierPartitionForceRestore(topicIdPartition, restoreUuid, header.startOffset(),
                            header.endOffset(), header.localMaterializedOffsetAndEpoch(), hash);
            objectStore.putObject(new TierObjectStore.TierStateRestoreSnapshotMetadata(restoreEvent), file,
                    TierObjectStore.FileType.TIER_STATE_SNAPSHOT);
            final RecordMetadata metadata = RecoveryUtils.injectTierTopicEvent(
                    producer, restoreEvent, tierTopicName, numTierTopicPartitions);
            System.out.println(String.format("Emitted tier topic recovery event: %s for %s",
                    metadata, header));
            return restoreEvent;
        }
    }

    private static String computeMd5(FileChannel fileChannel) throws IOException,
            NoSuchAlgorithmException {
        final MessageDigest digest = MessageDigest.getInstance("MD5");
        if (fileChannel.size() == 0)
            throw new IllegalArgumentException("Empty FileChannel supplied to computeMd5.");

        if (fileChannel.size() > Integer.MAX_VALUE)
            throw new IllegalArgumentException("File exceeds maximum size of " + Integer.MAX_VALUE + " vs " + fileChannel.size());

        final ByteBuffer buffer = ByteBuffer.allocate(Math.min(8 * 1024, (int) fileChannel.size()));
        long position = 0;
        int read;
        while ((read = fileChannel.read(buffer, position)) > 0) {
            buffer.flip();
            digest.update(buffer);
            buffer.clear();
            position += read;
        }

        return String.format("%032x", new BigInteger(1, digest.digest()));
    }

    public static void main(String[] args) throws Exception {
        runMain(args);
    }

    public static void runMain(String[] args) throws Exception {
        final ArgumentParser parser = TierPartitionStateRestoreTrigger.createArgParser();
        try {
            run(parser, parser.parseArgs(args));
        } catch (ArgumentParserException e) {
            parser.handleError(e);
            throw e;
        }
    }
}
